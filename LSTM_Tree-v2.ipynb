{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# boilerplate\n",
    "import random\n",
    "import tensorflow as tf\n",
    "sess = tf.InteractiveSession()\n",
    "import tensorflow_fold as td\n",
    "import gensim\n",
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "UNK = 'UNK'\n",
    "# This file contains the dataset in a useful way. We populate a list of\n",
    "# Trees to train/test our Neural Nets such that each Tree contains any\n",
    "# number of Node objects.\n",
    "\n",
    "# The best way to get a feel for how these objects are used in the program is to drop pdb.set_trace() in a few places throughout the codebase\n",
    "# to see how the trees are used.. look where loadtrees() is called etc..\n",
    "\n",
    "class Node:  # a node in the tree\n",
    "    def __init__(self, label = None, word=None):\n",
    "        self.label = label\n",
    "        self.word = word\n",
    "        self.parent = None  # reference to parent\n",
    "        self.left = None  # reference to left child\n",
    "        self.right = None  # reference to right child\n",
    "        # true if I am a leaf (could have probably derived this from if I have\n",
    "        # a word)\n",
    "        self.isLeaf = False\n",
    "        # true if we have finished performing fowardprop on this node (note,\n",
    "        # there are many ways to implement the recursion.. some might not\n",
    "        # require this flag)\n",
    "        self.level = 0\n",
    "        #defeault intitialziation of depth\n",
    "        self.has_label = False\n",
    "           \n",
    "class Tree:\n",
    "\n",
    "    def __init__(self, treeString, openChar='(', closeChar=')', label_size = 18):\n",
    "        tokens = []\n",
    "        self.open = '('\n",
    "        self.close = ')'\n",
    "        for toks in treeString.strip().split():\n",
    "            tokens += list(toks)\n",
    "        self.root = self.parse(tokens, label_size = label_size)\n",
    "          \n",
    "        self.self_binarize()\n",
    "        self.depth = get_depth(self.root)\n",
    "        self.levels = max(math.floor(math.log(float(self.depth)) / math.log(float(2)))-1, 0)\n",
    "        self.binary = check_for_binarization(self.root)\n",
    "        #propagate_label(self.root, self.levels, self.depth)\n",
    "        self.labels = get_labels(self.root)\n",
    "        self.labelcount = count_labels(self.root)\n",
    "\n",
    "    def parse(self, tokens, parent=None, label_size = 18):\n",
    "        \n",
    "        assert tokens[0] == self.open, \"Malformed tree\"\n",
    "        assert tokens[-1] == self.close, \"Malformed tree\"\n",
    "        \n",
    "        split = 1  # position after open \n",
    "        marker  = 1\n",
    "        countOpen = countClose = 0\n",
    "        label = None\n",
    "        if (split + label_size) < len(tokens):\n",
    "         str1 = ''.join(tokens[split: (split + label_size)])\n",
    "         if str1.isdigit():\n",
    "        \n",
    "            label = tokens[split: (split + label_size)]\n",
    "            label = np.asarray(label).astype(int)\n",
    "            split += label_size\n",
    "            marker += label_size \n",
    "                \n",
    "        if tokens[split] == self.open:\n",
    "            countOpen += 1\n",
    "            split += 1\n",
    "        # Find where left child and right child split\n",
    "        while countOpen != countClose:\n",
    "            if tokens[split] == self.open:\n",
    "                countOpen += 1\n",
    "            if tokens[split] == self.close:\n",
    "                countClose += 1\n",
    "            split += 1\n",
    "\n",
    "        # New node\n",
    "        if isinstance(label, np.ndarray):\n",
    "         node = Node(label)  \n",
    "         node.has_label = True\n",
    "        else:\n",
    "         node = Node()   \n",
    "        \n",
    "        if parent: \n",
    "         node.parent = parent\n",
    "         node.level = parent.level + 1\n",
    "\n",
    "        # leaf Node\n",
    "        if countOpen == 0:\n",
    "            node.word = ''.join(tokens[marker:-1])  # distinguish between lower and upper. Important for words like Apple\n",
    "            node.isLeaf = True\n",
    "            return node\n",
    "\n",
    "        node.left = self.parse(tokens[marker:split], parent=node)\n",
    "        if  (tokens[split] == self.open) :\n",
    "         node.right = self.parse(tokens[split:-1], parent=node)\n",
    "\n",
    "        return node\n",
    "     \n",
    "\n",
    "    def get_words(self):\n",
    "        leaves = getLeaves(self.root)\n",
    "        words = [node.word for node in leaves]\n",
    "        return words\n",
    "\n",
    "    def self_binarize(self):\n",
    "     \n",
    "     def binarize_tree(node):\n",
    "      \n",
    "      if node.isLeaf:\n",
    "       return\n",
    "      elif ((node.left is not None) & (node.right is not None)):\n",
    "       binarize_tree(node.left)\n",
    "       binarize_tree(node.right)\n",
    "      else:\n",
    "       #fuse parent node with child node\n",
    "       node.left.label = node.label\n",
    "       node.left.level -= 1\n",
    "       \n",
    "       if (node.level != 0):\n",
    "        if (node.parent.right is node):\n",
    "          node.parent.right = node.left\n",
    "        else:\n",
    "          node.parent.left = node.left \n",
    "        node.left.parent = node.parent\n",
    "       \n",
    "       else:\n",
    "        self.root = node.left\n",
    "        node.left.parent = None\n",
    "        self.root.has_label = True\n",
    "       \n",
    "       binarize_tree(node.left)\n",
    "     binarize_tree(self.root)\n",
    "\n",
    "def check_for_binarization(node):\n",
    "      \n",
    "      if node.isLeaf:\n",
    "        return True\n",
    "      elif (node.right is None):\n",
    "        return False \n",
    "      else:\n",
    "       b1 = check_for_binarization(node.left) \n",
    "       b2 = check_for_binarization(node.right)\n",
    "      return (b1 & b2)\n",
    "         \n",
    "def count_labels(node):\n",
    "    if node is None:\n",
    "     return 0\n",
    "    if node.has_label == False:\n",
    "     return 0\n",
    "    count = 0\n",
    "    if node.has_label == True:\n",
    "      count = 1\n",
    "      return count + count_labels(node.left) + count_labels(node.right)\n",
    "    \n",
    " \n",
    "def binarize(node):\n",
    "     \n",
    "      if node.isLeaf:\n",
    "       return\n",
    "      elif ((node.left is not None) & (node.right is not None)):\n",
    "       binarize(node.left)\n",
    "       binarize(node.right)\n",
    "      else:\n",
    "       #fuse parent node with child node\n",
    "       node.left.label = node.label\n",
    "       node.left.level -= 1\n",
    "       if (node.parent.right is node):\n",
    "        node.parent.right = node.left\n",
    "       else:\n",
    "        node.parent.left = node.left\n",
    "       node.left.parent = node.parent\n",
    "       binarize(node.left)\n",
    "\n",
    "\n",
    "\n",
    "def get_depth(node):\n",
    "    if node is None:\n",
    "         return\n",
    "\n",
    "    if node.isLeaf:\n",
    "      return 0\n",
    "    return (1+ max(get_depth(node.left), get_depth(node.right)))  \n",
    "        \n",
    "def propagate_label(node, levels, depth):\n",
    "    \n",
    "    if node is None:\n",
    "         return\n",
    "    if (node.level > levels):\n",
    "    #if (node.level > levels) or ((get_depth(node) + node.level) < depth): \n",
    "         return\n",
    "    \n",
    "    if node.parent:\n",
    "     node.label = node.parent.label\n",
    "     node.has_label = True\n",
    "    propagate_label(node.left, levels, depth)\n",
    "    propagate_label(node.right, levels, depth)\n",
    "\n",
    "   \n",
    "\n",
    "def leftTraverse(node, nodeFn=None, args=None):\n",
    "    \"\"\"\n",
    "    Recursive function traverses tree\n",
    "    from left to right. \n",
    "    Calls nodeFn at each node\n",
    "    \"\"\"\n",
    "    if node is None:\n",
    "        return\n",
    "    leftTraverse(node.left, nodeFn, args)\n",
    "    leftTraverse(node.right, nodeFn, args)\n",
    "    nodeFn(node, args)\n",
    "\n",
    "\n",
    "def getLeaves(node):\n",
    "    if node is None:\n",
    "        return []\n",
    "    if node.isLeaf:\n",
    "        return [node]\n",
    "    else:\n",
    "        return getLeaves(node.left) + getLeaves(node.right)\n",
    "\n",
    "\n",
    "def get_labels(node):\n",
    "    if node is None:\n",
    "        return []\n",
    "    if node.has_label == False:\n",
    "        return []\n",
    "    return get_labels(node.left) + get_labels(node.right) + [node.label]\n",
    "\n",
    "\n",
    "\n",
    "def clearFprop(node, words):\n",
    "    node.fprop = False\n",
    "\n",
    "\n",
    "def loadTrees(dataSet='train'):\n",
    "    \"\"\"\n",
    "    Loads training trees. Maps leaf node words to word ids.\n",
    "    \"\"\"\n",
    "    file = 'trees/%s.txt' % dataSet\n",
    "    print (\"Loading %s trees..\" % dataSet)\n",
    "    with open(file, 'r') as fid:\n",
    "        \n",
    "        trees = [Tree(l) for l in fid.readlines()]\n",
    "\n",
    "    return trees\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def loadmodel():\n",
    "    print(\"Loading Google Word2vecs....\")\n",
    "    model = gensim.models.KeyedVectors.load_word2vec_format('./GoogleNews-vectors-negative300.bin.gz', binary = True)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading train trees..\n",
      "Loading dev trees..\n",
      "Loading test trees..\n"
     ]
    }
   ],
   "source": [
    "train_trees = loadTrees('train')\n",
    "dev_trees = loadTrees('dev')\n",
    "test_trees = loadTrees('test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_nodes = [t.root for t in train_trees]\n",
    "dev_nodes = [t.root for t in dev_trees]\n",
    "test_nodes = [t.root for t in test_trees]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Google Word2vecs....\n"
     ]
    }
   ],
   "source": [
    "model = loadmodel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def filter_model(model):\n",
    "    filtered_dict = {}\n",
    "    trees = loadTrees('train') + loadTrees('dev') + loadTrees('test')\n",
    "    words = [t.get_words() for t in trees]\n",
    "    vocab = set()\n",
    "    for word in words:\n",
    "        vocab.update(word)\n",
    "    for word in vocab:\n",
    "        if word in model.vocab:\n",
    "            filtered_dict[word] = model[word]\n",
    "    return filtered_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading train trees..\n",
      "Loading dev trees..\n",
      "Loading test trees..\n"
     ]
    }
   ],
   "source": [
    "filtered_model = filter_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_embeddings(filtered_model):\n",
    "  \"\"\"Loads embedings, returns weight matrix and dict from words to indices.\"\"\"\n",
    "  print('loading word embeddings')\n",
    "  weight_vectors = []\n",
    "  word_idx = {}\n",
    "  for word, vector in filtered_model.items():\n",
    "    word_idx[word] = len(weight_vectors)\n",
    "    weight_vectors.append(np.array(vector, dtype=np.float32))\n",
    "  # Random embedding vector for unknown words.\n",
    "  weight_vectors.append(np.random.uniform(\n",
    "      -0.05, 0.05, weight_vectors[0].shape).astype(np.float32))\n",
    "  return np.stack(weight_vectors), word_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading word embeddings\n"
     ]
    }
   ],
   "source": [
    "weight_matrix, word_idx = load_embeddings(filtered_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class BinaryTreeLSTMCell(tf.contrib.rnn.BasicLSTMCell):\n",
    "  \"\"\"LSTM with two state inputs.\n",
    "\n",
    "  This is the model described in section 3.2 of 'Improved Semantic\n",
    "  Representations From Tree-Structured Long Short-Term Memory\n",
    "  Networks' <http://arxiv.org/pdf/1503.00075.pdf>, with recurrent\n",
    "  dropout as described in 'Recurrent Dropout without Memory Loss'\n",
    "  <http://arxiv.org/pdf/1603.05118.pdf>.\n",
    "  \"\"\"\n",
    "\n",
    "  def __init__(self, num_units, keep_prob=1.0):\n",
    "    \"\"\"Initialize the cell.\n",
    "\n",
    "    Args:\n",
    "      num_units: int, The number of units in the LSTM cell.\n",
    "      keep_prob: Keep probability for recurrent dropout.\n",
    "    \"\"\"\n",
    "    super(BinaryTreeLSTMCell, self).__init__(num_units)\n",
    "    self._keep_prob = keep_prob\n",
    "\n",
    "  def __call__(self, inputs, state, scope=None):\n",
    "    with tf.variable_scope(scope or type(self).__name__):\n",
    "      lhs, rhs = state\n",
    "      c0, h0 = lhs\n",
    "      c1, h1 = rhs\n",
    "      concat = tf.contrib.layers.linear(\n",
    "          tf.concat([inputs, h0, h1], 1), 5 * self._num_units)\n",
    "\n",
    "      # i = input_gate, j = new_input, f = forget_gate, o = output_gate\n",
    "      i, j, f0, f1, o = tf.split(value=concat, num_or_size_splits=5, axis=1)\n",
    "\n",
    "      j = self._activation(j)\n",
    "      if not isinstance(self._keep_prob, float) or self._keep_prob < 1:\n",
    "        j = tf.nn.dropout(j, self._keep_prob)\n",
    "\n",
    "      new_c = (c0 * tf.sigmoid(f0 + self._forget_bias) +\n",
    "               c1 * tf.sigmoid(f1 + self._forget_bias) +\n",
    "               tf.sigmoid(i) * j)\n",
    "      new_h = self._activation(new_c) * tf.sigmoid(o)\n",
    "\n",
    "      new_state = tf.contrib.rnn.LSTMStateTuple(new_c, new_h)\n",
    "\n",
    "      return new_h, new_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "keep_prob_ph = tf.placeholder_with_default(1.0, [])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lstm_num_units = 300  # Tai et al. used 150, but our regularization strategy is more effective\n",
    "tree_lstm = td.ScopedLayer(\n",
    "      tf.contrib.rnn.DropoutWrapper(\n",
    "          BinaryTreeLSTMCell(lstm_num_units, keep_prob=keep_prob_ph),\n",
    "          input_keep_prob=keep_prob_ph, output_keep_prob=keep_prob_ph),\n",
    "      name_or_scope='tree_lstm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "NUM_ASPECTS = 18  # number of aspects\n",
    "NUM_POLARITY = 4 #number of polarity classes assicated with an aspect (1 = mildly +ve or -ve, 2 = negative, 3 = positive)\n",
    "output_layer = td.FC(NUM_ASPECTS*NUM_POLARITY, activation=None, input_keep_prob=0.9,  name='output_layer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "word_embedding = td.Embedding(\n",
    "    *weight_matrix.shape, initializer=weight_matrix, name='word_embedding', trainable = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "embed_subtree = td.ForwardDeclaration(name='embed_subtree')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def logits_and_state():\n",
    "  \"\"\"Creates a block that goes from tokens to (logits, state) tuples.\"\"\"\n",
    "  unknown_idx = len(word_idx)\n",
    "  lookup_word = lambda word: word_idx.get(word, unknown_idx)\n",
    "  \n",
    "  word2vec = (td.GetItem(0) >> td.InputTransform(lookup_word) >>\n",
    "              td.Scalar('int32') >> word_embedding)\n",
    "\n",
    "  pair2vec = (embed_subtree(), embed_subtree())\n",
    "\n",
    "  # Trees are binary, so the tree layer takes two states as its input_state.\n",
    "  zero_state = td.Zeros((tree_lstm.state_size,) * 2)\n",
    "  # Input is a word vector.\n",
    "  zero_inp = td.Zeros(word_embedding.output_type.shape[0])\n",
    "\n",
    "  word_case = td.AllOf(word2vec, zero_state)\n",
    "  pair_case = td.AllOf(zero_inp, pair2vec)\n",
    "\n",
    "  tree2vec = td.OneOf(len, [(1, word_case), (2, pair_case)])\n",
    "\n",
    "  return tree2vec >> tree_lstm >> (output_layer, td.Identity())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tf_node_loss(logits, labels):\n",
    "  #mask = (labels > 0)\n",
    "  #actuals = tf.cast(mask, tf.int32) #binarize the labels to compute loss for aspect detection \n",
    "  logits2 = tf.reshape(logits, [-1, NUM_ASPECTS,  NUM_POLARITY])\n",
    " \n",
    "  #logits3 = tf.slice(logits2, [0,0,0], [-1,-1, 2])\n",
    "  #logits4 = tf.slice(logits2, [0,0,1], [-1,-1, -1])\n",
    "  #labels2 = tf.boolean_mask(labels, mask) -1\n",
    "  #logits5 = tf.boolean_mask(logits4, mask )\n",
    "  #loss1 = tf.reduce_sum(tf.nn.sparse_softmax_cross_entropy_with_logits(logits = logits5, labels=labels2))\n",
    "  loss2 = tf.reduce_sum(tf.nn.sparse_softmax_cross_entropy_with_logits(logits = logits2, labels=labels), axis = 1)\n",
    "  #loss3 = tf.reduce_sum(tf.nn.sparse_softmax_cross_entropy_with_logits(logits = logits4, labels=labels), axis = 1)\n",
    "  return loss2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tf_tpr(logits, labels):\n",
    "  logits2 = tf.nn.softmax(tf.reshape(logits, [-1, NUM_ASPECTS, NUM_POLARITY]))\n",
    "  predictions2 = ( logits2[:,:, 1] ) > (logits2[:,:, 0])\n",
    " \n",
    "  predictions3 = tf.cast(predictions2, tf.float64)\n",
    " \n",
    "  actuals1 = labels > 0\n",
    "  actuals2 = tf.cast(actuals1, tf.float64)\n",
    "\n",
    "  ones_like_actuals = tf.ones_like(actuals2)\n",
    "  zeros_like_actuals = tf.zeros_like(actuals2)\n",
    "  ones_like_predictions = tf.ones_like(predictions3)\n",
    "  zeros_like_predictions = tf.zeros_like(predictions3)\n",
    "\n",
    "  ans = tf.reduce_sum(\n",
    "    tf.cast(\n",
    "      tf.logical_and(\n",
    "           tf.equal(actuals2, ones_like_actuals), \n",
    "           tf.equal(predictions3, ones_like_predictions)\n",
    "      ), \n",
    "      tf.float64\n",
    "    ), axis = 1\n",
    "  )\n",
    "\n",
    "  return ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tf_tnr(logits, labels):\n",
    "  logits2 = tf.nn.softmax(tf.reshape(logits, [-1, NUM_ASPECTS,  NUM_POLARITY]))\n",
    "  predictions2 = ( logits2[:,:, 1] ) > (logits2[:,:, 0])\n",
    "  #predictions =tf.cast(tf.argmax(logits2, 2), tf.int32)\n",
    "  #predictions2 = predictions > 0\n",
    "  predictions3 = tf.cast(predictions2, tf.float64)\n",
    "  #actuals =  tf.reshape(labels, [-1, 1])\n",
    "  actuals1 = labels > 0\n",
    "  actuals2 = tf.cast(actuals1, tf.float64)\n",
    "\n",
    "  ones_like_actuals = tf.ones_like(actuals2)\n",
    "  zeros_like_actuals = tf.zeros_like(actuals2)\n",
    "  ones_like_predictions = tf.ones_like(predictions3)\n",
    "  zeros_like_predictions = tf.zeros_like(predictions3)\n",
    "\n",
    "  ans = tf.reduce_sum(\n",
    "    tf.cast(\n",
    "      tf.logical_and(\n",
    "           tf.equal(actuals2, zeros_like_actuals), \n",
    "           tf.equal(predictions3, zeros_like_predictions)\n",
    "      ), \n",
    "      tf.float64\n",
    "    ), axis = 1\n",
    "  )\n",
    "\n",
    "  return ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tf_fpr(logits, labels):\n",
    "  logits2 = tf.nn.softmax(tf.reshape(logits, [-1, NUM_ASPECTS,  NUM_POLARITY]))\n",
    "  predictions2 = ( logits2[:,:, 1] ) > (logits2[:,:, 0])\n",
    "  #predictions =tf.cast(tf.argmax(logits2, 2), tf.int32)\n",
    "  #predictions2 = predictions > 0\n",
    "  predictions3 = tf.cast(predictions2, tf.float64)\n",
    "  #actuals =  tf.reshape(labels, [-1, 1])\n",
    "  actuals1 = labels > 0\n",
    "  actuals2 = tf.cast(actuals1, tf.float64)\n",
    "\n",
    "  ones_like_actuals = tf.ones_like(actuals2)\n",
    "  zeros_like_actuals = tf.zeros_like(actuals2)\n",
    "  ones_like_predictions = tf.ones_like(predictions3)\n",
    "  zeros_like_predictions = tf.zeros_like(predictions3)\n",
    "\n",
    "  ans = tf.reduce_sum(\n",
    "    tf.cast(\n",
    "      tf.logical_and(\n",
    "           tf.equal(actuals2, zeros_like_actuals), \n",
    "           tf.equal(predictions3, ones_like_predictions)\n",
    "      ), \n",
    "      tf.float64\n",
    "    ), axis = 1\n",
    "  )\n",
    "\n",
    "  return ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tf_fnr(logits, labels):\n",
    "  logits2 = tf.nn.softmax(tf.reshape(logits, [-1, NUM_ASPECTS,  NUM_POLARITY]))\n",
    "  predictions2 = ( logits2[:,:, 1] ) > (logits2[:,:, 0])\n",
    "  predictions3 = tf.cast(predictions2, tf.float64)\n",
    "  actuals1 = labels > 0\n",
    "  actuals2 = tf.cast(actuals1, tf.float64)\n",
    "\n",
    "  ones_like_actuals = tf.ones_like(actuals2)\n",
    "  zeros_like_actuals = tf.zeros_like(actuals2)\n",
    "  ones_like_predictions = tf.ones_like(predictions3)\n",
    "  zeros_like_predictions = tf.zeros_like(predictions3)\n",
    "\n",
    "  ans = tf.reduce_sum(\n",
    "    tf.cast(\n",
    "      tf.logical_and(\n",
    "           tf.equal(actuals2, ones_like_actuals), \n",
    "           tf.equal(predictions3, zeros_like_predictions)\n",
    "      ), \n",
    "      tf.float64\n",
    "    ), axis = 1\n",
    "  )\n",
    "\n",
    "  return ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def add_metrics(is_root, is_neutral):\n",
    "  \"\"\"A block that adds metrics for loss and hits; output is the LSTM state.\"\"\"\n",
    "  c = td.Composition(\n",
    "      name='predict(is_root=%s, is_neutral=%s)' % (is_root, is_neutral))\n",
    "  with c.scope():\n",
    "    # destructure the input; (labels, neutral, (logits, state))\n",
    "    labels = c.input[0]\n",
    "    logits = td.GetItem(0).reads(c.input[2])\n",
    "    state = td.GetItem(1).reads(c.input[2])\n",
    "\n",
    "    loss = td.Function(tf_node_loss)\n",
    "    td.Metric('all_loss').reads(loss.reads(logits, labels))\n",
    "    if is_root: td.Metric('root_loss').reads(loss)\n",
    "   \n",
    "    tpr = td.Function(tf_tpr)\n",
    "    tnr = td.Function(tf_tnr)\n",
    "    fpr = td.Function(tf_fpr)\n",
    "    fnr = td.Function(tf_fnr)\n",
    "    td.Metric('all_tpr').reads(tpr.reads(logits, labels))\n",
    "    td.Metric('all_tnr').reads(tnr.reads(logits, labels))\n",
    "    td.Metric('all_fpr').reads(fpr.reads(logits, labels))\n",
    "    td.Metric('all_fnr').reads(fnr.reads(logits, labels))                           \n",
    "    if is_root: \n",
    "        td.Metric('tpr').reads(tpr)\n",
    "        td.Metric('tnr').reads(tnr)\n",
    "        td.Metric('fpr').reads(fpr)\n",
    "        td.Metric('fnr').reads(fnr)\n",
    "   \n",
    "    # output the state, which will be read by our by parent's LSTM cell\n",
    "    c.output.reads(state)\n",
    "  return c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tokenize(node):\n",
    "  group = []\n",
    "  neutral = '2'\n",
    "  if node.has_label:\n",
    "  \n",
    "    label = node.label\n",
    "    \n",
    "    neutral = '1'\n",
    "  else:\n",
    "    label = np.zeros((NUM_ASPECTS,),dtype=np.int)\n",
    "    \n",
    "  if node.isLeaf:\n",
    "    group = [node.word]\n",
    "  else:\n",
    "    group = [node.left, node.right]\n",
    "  return label, neutral, group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "(18,)\n"
     ]
    }
   ],
   "source": [
    "node = train_nodes[0]\n",
    "label, neutral, group = tokenize(node)\n",
    "print (len(group))\n",
    "print (label.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def embed_tree(logits_and_state, is_root):\n",
    "  \"\"\"Creates a block that embeds trees; output is tree LSTM state.\"\"\"\n",
    "  return td.InputTransform(tokenize) >> td.OneOf(\n",
    "      key_fn=lambda pair: pair[1] == '2',  # label 2 means neutral\n",
    "      case_blocks=(add_metrics(is_root, is_neutral=False),\n",
    "                   add_metrics(is_root, is_neutral=True)),\n",
    "      pre_block=(td.Vector(NUM_ASPECTS, dtype = 'int32'), td.Scalar('int32'), logits_and_state))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = embed_tree(logits_and_state(), is_root=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "embed_subtree.resolve_to(embed_tree(logits_and_state(), is_root=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input type: PyObjectType()\n",
      "output type: TupleType(TensorType((300,), 'float32'), TensorType((300,), 'float32'))\n"
     ]
    }
   ],
   "source": [
    "compiler = td.Compiler.create(model)\n",
    "print('input type: %s' % model.input_type)\n",
    "print('output type: %s' % model.output_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "metrics = {k: tf.reduce_mean(v) for k, v in compiler.metric_tensors.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "LEARNING_RATE = 0.05\n",
    "KEEP_PROB = 0.6\n",
    "BATCH_SIZE = 25\n",
    "EPOCHS = 100\n",
    "EMBEDDING_LEARNING_RATE_FACTOR = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/impadmin/anaconda2/envs/LSTM/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py:91: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    }
   ],
   "source": [
    "train_feed_dict = {keep_prob_ph: KEEP_PROB}\n",
    "loss = tf.reduce_mean(compiler.metric_tensors['root_loss'])\n",
    "opt = tf.train.AdagradOptimizer(LEARNING_RATE)\n",
    "train = opt.minimize(loss)\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_step(batch):\n",
    "  train_feed_dict[compiler.loom_input_tensor] = batch\n",
    "  _, batch_loss = sess.run([train, loss], train_feed_dict)\n",
    "  return batch_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_epoch(train_set):\n",
    "  list = [train_step(batch) for batch in td.group_by_batches(train_set, BATCH_SIZE)]\n",
    "  return sum(list)/ max(len(list), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_set = compiler.build_loom_inputs(train_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dev_feed_dict = compiler.build_feed_dict(dev_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def dev_eval(epoch, train_loss):\n",
    "  dev_metrics = sess.run(metrics, dev_feed_dict)\n",
    "  dev_loss = dev_metrics['root_loss']\n",
    "\n",
    "  tp = dev_metrics['tpr']\n",
    "  tn = dev_metrics['tnr']\n",
    "  fp = dev_metrics['fpr']\n",
    "  fn = dev_metrics['fnr']\n",
    "  \n",
    "  tpr = float(tp)/(float(tp) + float(fn))\n",
    "  fpr = float(fp)/(float(tp) + float(fn))\n",
    "\n",
    "  \n",
    "\n",
    "  recall = tpr\n",
    "  if (float(tp) + float(fp)) > 0:\n",
    "   precision = float(tp)/(float(tp) + float(fp))\n",
    "  else: precision = 0.\n",
    "  if precision + recall > 0:\n",
    "   f1_score = (2 * (precision * recall)) / (precision + recall)\n",
    "  else: f1_score = 0.\n",
    " \n",
    " \n",
    "  print('epoch:%4d, train_loss: %.3e, dev_loss: %.3e,Task1 Precision: %.3e, Task1 Recall: %.3e, Task1 F1 score: %.3e'\n",
    "        % (epoch, train_loss, dev_loss, precision, recall, f1_score))\n",
    "  return f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-39-9f5dc04c7c68>, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-39-9f5dc04c7c68>\"\u001b[0;36m, line \u001b[0;32m3\u001b[0m\n\u001b[0;31m    session.close()n locals() and session is not None:\u001b[0m\n\u001b[0m                   ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "if 'session' in locals() and session is not None:\n",
    "    print('Close interactive session')\n",
    "    session.close()n locals() and session is not None:\n",
    "    print('Close interactive session')\n",
    "    session.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "InternalError",
     "evalue": "Blas SGEMM launch failed : a.shape=(340, 900), b.shape=(900, 1500), m=340, n=1500, k=900\n\t [[Node: while/Function_35/tree_lstm/fully_connected/MatMul = MatMul[T=DT_FLOAT, transpose_a=false, transpose_b=false, _device=\"/job:localhost/replica:0/task:0/gpu:0\"](while/Function_35/tree_lstm/concat, while/Function_17/tree_lstm/fully_connected/MatMul/Enter)]]\n\t [[Node: while/Function_6/SparseSoftmaxCrossEntropyWithLogits/Shape_1/_109 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/gpu:0\", send_device_incarnation=1, tensor_name=\"edge_2569_while/Function_6/SparseSoftmaxCrossEntropyWithLogits/Shape_1\", tensor_type=DT_INT32, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](^_cloopwhile/Function_6/arg_1/Gather/_11)]]\n\nCaused by op 'while/Function_35/tree_lstm/fully_connected/MatMul', defined at:\n  File \"/home/impadmin/anaconda2/envs/LSTM/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/home/impadmin/anaconda2/envs/LSTM/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/home/impadmin/anaconda2/envs/LSTM/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/home/impadmin/anaconda2/envs/LSTM/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/home/impadmin/anaconda2/envs/LSTM/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 477, in start\n    ioloop.IOLoop.instance().start()\n  File \"/home/impadmin/anaconda2/envs/LSTM/lib/python3.6/site-packages/zmq/eventloop/ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"/home/impadmin/anaconda2/envs/LSTM/lib/python3.6/site-packages/tornado/ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"/home/impadmin/anaconda2/envs/LSTM/lib/python3.6/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/impadmin/anaconda2/envs/LSTM/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/home/impadmin/anaconda2/envs/LSTM/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/home/impadmin/anaconda2/envs/LSTM/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/home/impadmin/anaconda2/envs/LSTM/lib/python3.6/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/impadmin/anaconda2/envs/LSTM/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/home/impadmin/anaconda2/envs/LSTM/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 235, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/home/impadmin/anaconda2/envs/LSTM/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/home/impadmin/anaconda2/envs/LSTM/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/impadmin/anaconda2/envs/LSTM/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 533, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/impadmin/anaconda2/envs/LSTM/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2698, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/impadmin/anaconda2/envs/LSTM/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2802, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/home/impadmin/anaconda2/envs/LSTM/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2862, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-29-5d37be798470>\", line 1, in <module>\n    compiler = td.Compiler.create(model)\n  File \"/home/impadmin/anaconda2/envs/LSTM/lib/python3.6/site-packages/tensorflow_fold/blocks/block_compiler.py\", line 260, in create\n    parallel_iterations, back_prop, swap_memory)\n  File \"/home/impadmin/anaconda2/envs/LSTM/lib/python3.6/site-packages/tensorflow_fold/blocks/block_compiler.py\", line 416, in init_loom\n    parallel_iterations, back_prop, swap_memory)\n  File \"/home/impadmin/anaconda2/envs/LSTM/lib/python3.6/site-packages/tensorflow_fold/blocks/block_compiler.py\", line 424, in _init_loom\n    back_prop=back_prop, swap_memory=swap_memory)\n  File \"/home/impadmin/anaconda2/envs/LSTM/lib/python3.6/site-packages/tensorflow_fold/blocks/block_compiler.py\", line 139, in create_tagged_loom\n    dry_run=dry_run, loom_input_tensor=loom_input_tensor)\n  File \"/home/impadmin/anaconda2/envs/LSTM/lib/python3.6/site-packages/tensorflow_fold/blocks/block_compiler.py\", line 41, in __init__\n    super(_TaggedLoom, self).__init__(*args, **kwargs)\n  File \"/home/impadmin/anaconda2/envs/LSTM/lib/python3.6/site-packages/tensorflow_fold/loom/loom.py\", line 410, in __init__\n    self._setup_network()\n  File \"/home/impadmin/anaconda2/envs/LSTM/lib/python3.6/site-packages/tensorflow_fold/loom/loom.py\", line 621, in _setup_network\n    swap_memory=self._swap_memory)[1:]\n  File \"/home/impadmin/anaconda2/envs/LSTM/lib/python3.6/site-packages/tensorflow/python/ops/control_flow_ops.py\", line 2626, in while_loop\n    result = context.BuildLoop(cond, body, loop_vars, shape_invariants)\n  File \"/home/impadmin/anaconda2/envs/LSTM/lib/python3.6/site-packages/tensorflow/python/ops/control_flow_ops.py\", line 2459, in BuildLoop\n    pred, body, original_loop_vars, loop_vars, shape_invariants)\n  File \"/home/impadmin/anaconda2/envs/LSTM/lib/python3.6/site-packages/tensorflow/python/ops/control_flow_ops.py\", line 2409, in _BuildLoop\n    body_result = body(*packed_vars_for_body)\n  File \"/home/impadmin/anaconda2/envs/LSTM/lib/python3.6/site-packages/tensorflow_fold/loom/loom.py\", line 614, in loop_body\n    new_state = self._construct_loom_layer(depth, state)\n  File \"/home/impadmin/anaconda2/envs/LSTM/lib/python3.6/site-packages/tensorflow_fold/loom/loom.py\", line 711, in _construct_loom_layer\n    op_outputs = op.instantiate_batch(arg_inputs)\n  File \"/home/impadmin/anaconda2/envs/LSTM/lib/python3.6/site-packages/tensorflow_fold/blocks/loom_ops.py\", line 66, in instantiate_batch\n    outputs = self.tf_fn(*inputs)\n  File \"/home/impadmin/anaconda2/envs/LSTM/lib/python3.6/site-packages/tensorflow_fold/blocks/layers.py\", line 550, in __call__\n    result = self._layer_fn(*args, scope=self._vscope)\n  File \"/home/impadmin/anaconda2/envs/LSTM/lib/python3.6/site-packages/tensorflow/contrib/rnn/python/ops/core_rnn_cell_impl.py\", line 524, in __call__\n    output, new_state = self._cell(inputs, state, scope)\n  File \"<ipython-input-11-931ade2f97ba>\", line 27, in __call__\n    tf.concat([inputs, h0, h1], 1), 5 * self._num_units)\n  File \"/home/impadmin/anaconda2/envs/LSTM/lib/python3.6/site-packages/tensorflow/contrib/framework/python/ops/arg_scope.py\", line 177, in func_with_args\n    return func(*args, **current_args)\n  File \"/home/impadmin/anaconda2/envs/LSTM/lib/python3.6/site-packages/tensorflow/contrib/layers/python/layers/layers.py\", line 1409, in fully_connected\n    outputs = layer.apply(inputs)\n  File \"/home/impadmin/anaconda2/envs/LSTM/lib/python3.6/site-packages/tensorflow/python/layers/base.py\", line 303, in apply\n    return self.__call__(inputs, **kwargs)\n  File \"/home/impadmin/anaconda2/envs/LSTM/lib/python3.6/site-packages/tensorflow/python/layers/base.py\", line 273, in __call__\n    outputs = self.call(inputs, **kwargs)\n  File \"/home/impadmin/anaconda2/envs/LSTM/lib/python3.6/site-packages/tensorflow/python/layers/core.py\", line 145, in call\n    outputs = standard_ops.matmul(inputs, self.kernel)\n  File \"/home/impadmin/anaconda2/envs/LSTM/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py\", line 1855, in matmul\n    a, b, transpose_a=transpose_a, transpose_b=transpose_b, name=name)\n  File \"/home/impadmin/anaconda2/envs/LSTM/lib/python3.6/site-packages/tensorflow/python/ops/gen_math_ops.py\", line 1454, in _mat_mul\n    transpose_b=transpose_b, name=name)\n  File \"/home/impadmin/anaconda2/envs/LSTM/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 763, in apply_op\n    op_def=op_def)\n  File \"/home/impadmin/anaconda2/envs/LSTM/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 2395, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"/home/impadmin/anaconda2/envs/LSTM/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1264, in __init__\n    self._traceback = _extract_stack()\n\nInternalError (see above for traceback): Blas SGEMM launch failed : a.shape=(340, 900), b.shape=(900, 1500), m=340, n=1500, k=900\n\t [[Node: while/Function_35/tree_lstm/fully_connected/MatMul = MatMul[T=DT_FLOAT, transpose_a=false, transpose_b=false, _device=\"/job:localhost/replica:0/task:0/gpu:0\"](while/Function_35/tree_lstm/concat, while/Function_17/tree_lstm/fully_connected/MatMul/Enter)]]\n\t [[Node: while/Function_6/SparseSoftmaxCrossEntropyWithLogits/Shape_1/_109 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/gpu:0\", send_device_incarnation=1, tensor_name=\"edge_2569_while/Function_6/SparseSoftmaxCrossEntropyWithLogits/Shape_1\", tensor_type=DT_INT32, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](^_cloopwhile/Function_6/arg_1/Gather/_11)]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInternalError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda2/envs/LSTM/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1021\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1022\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1023\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/LSTM/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1003\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1004\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m   1005\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/LSTM/lib/python3.6/contextlib.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type, value, traceback)\u001b[0m\n\u001b[1;32m     88\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m                 \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/LSTM/lib/python3.6/site-packages/tensorflow/python/framework/errors_impl.py\u001b[0m in \u001b[0;36mraise_exception_on_not_ok_status\u001b[0;34m()\u001b[0m\n\u001b[1;32m    468\u001b[0m           \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpywrap_tensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 469\u001b[0;31m           pywrap_tensorflow.TF_GetCode(status))\n\u001b[0m\u001b[1;32m    470\u001b[0m   \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInternalError\u001b[0m: Blas SGEMM launch failed : a.shape=(340, 900), b.shape=(900, 1500), m=340, n=1500, k=900\n\t [[Node: while/Function_35/tree_lstm/fully_connected/MatMul = MatMul[T=DT_FLOAT, transpose_a=false, transpose_b=false, _device=\"/job:localhost/replica:0/task:0/gpu:0\"](while/Function_35/tree_lstm/concat, while/Function_17/tree_lstm/fully_connected/MatMul/Enter)]]\n\t [[Node: while/Function_6/SparseSoftmaxCrossEntropyWithLogits/Shape_1/_109 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/gpu:0\", send_device_incarnation=1, tensor_name=\"edge_2569_while/Function_6/SparseSoftmaxCrossEntropyWithLogits/Shape_1\", tensor_type=DT_INT32, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](^_cloopwhile/Function_6/arg_1/Gather/_11)]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mInternalError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-39-8d366d2aac82>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0msave_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'weights/sentiment_model'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffled\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEPOCHS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m   \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshuffled\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m   \u001b[0mf1_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdev_eval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-35-4ea0199acd14>\u001b[0m in \u001b[0;36mtrain_epoch\u001b[0;34m(train_set)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtrain_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_set\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m   \u001b[0mlist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtrain_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroup_by_batches\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-35-4ea0199acd14>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtrain_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_set\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m   \u001b[0mlist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtrain_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroup_by_batches\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-34-f9dac2895704>\u001b[0m in \u001b[0;36mtrain_step\u001b[0;34m(batch)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtrain_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m   \u001b[0mtrain_feed_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcompiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloom_input_tensor\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m   \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_feed_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mbatch_loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/LSTM/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    765\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    766\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 767\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    768\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    769\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/LSTM/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    963\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    964\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 965\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    966\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    967\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/LSTM/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1013\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1014\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1015\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1016\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1017\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m~/anaconda2/envs/LSTM/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1033\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1034\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1035\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1036\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1037\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInternalError\u001b[0m: Blas SGEMM launch failed : a.shape=(340, 900), b.shape=(900, 1500), m=340, n=1500, k=900\n\t [[Node: while/Function_35/tree_lstm/fully_connected/MatMul = MatMul[T=DT_FLOAT, transpose_a=false, transpose_b=false, _device=\"/job:localhost/replica:0/task:0/gpu:0\"](while/Function_35/tree_lstm/concat, while/Function_17/tree_lstm/fully_connected/MatMul/Enter)]]\n\t [[Node: while/Function_6/SparseSoftmaxCrossEntropyWithLogits/Shape_1/_109 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/gpu:0\", send_device_incarnation=1, tensor_name=\"edge_2569_while/Function_6/SparseSoftmaxCrossEntropyWithLogits/Shape_1\", tensor_type=DT_INT32, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](^_cloopwhile/Function_6/arg_1/Gather/_11)]]\n\nCaused by op 'while/Function_35/tree_lstm/fully_connected/MatMul', defined at:\n  File \"/home/impadmin/anaconda2/envs/LSTM/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/home/impadmin/anaconda2/envs/LSTM/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/home/impadmin/anaconda2/envs/LSTM/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/home/impadmin/anaconda2/envs/LSTM/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/home/impadmin/anaconda2/envs/LSTM/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 477, in start\n    ioloop.IOLoop.instance().start()\n  File \"/home/impadmin/anaconda2/envs/LSTM/lib/python3.6/site-packages/zmq/eventloop/ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"/home/impadmin/anaconda2/envs/LSTM/lib/python3.6/site-packages/tornado/ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"/home/impadmin/anaconda2/envs/LSTM/lib/python3.6/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/impadmin/anaconda2/envs/LSTM/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/home/impadmin/anaconda2/envs/LSTM/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/home/impadmin/anaconda2/envs/LSTM/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/home/impadmin/anaconda2/envs/LSTM/lib/python3.6/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/impadmin/anaconda2/envs/LSTM/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/home/impadmin/anaconda2/envs/LSTM/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 235, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/home/impadmin/anaconda2/envs/LSTM/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/home/impadmin/anaconda2/envs/LSTM/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/impadmin/anaconda2/envs/LSTM/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 533, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/impadmin/anaconda2/envs/LSTM/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2698, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/impadmin/anaconda2/envs/LSTM/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2802, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/home/impadmin/anaconda2/envs/LSTM/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2862, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-29-5d37be798470>\", line 1, in <module>\n    compiler = td.Compiler.create(model)\n  File \"/home/impadmin/anaconda2/envs/LSTM/lib/python3.6/site-packages/tensorflow_fold/blocks/block_compiler.py\", line 260, in create\n    parallel_iterations, back_prop, swap_memory)\n  File \"/home/impadmin/anaconda2/envs/LSTM/lib/python3.6/site-packages/tensorflow_fold/blocks/block_compiler.py\", line 416, in init_loom\n    parallel_iterations, back_prop, swap_memory)\n  File \"/home/impadmin/anaconda2/envs/LSTM/lib/python3.6/site-packages/tensorflow_fold/blocks/block_compiler.py\", line 424, in _init_loom\n    back_prop=back_prop, swap_memory=swap_memory)\n  File \"/home/impadmin/anaconda2/envs/LSTM/lib/python3.6/site-packages/tensorflow_fold/blocks/block_compiler.py\", line 139, in create_tagged_loom\n    dry_run=dry_run, loom_input_tensor=loom_input_tensor)\n  File \"/home/impadmin/anaconda2/envs/LSTM/lib/python3.6/site-packages/tensorflow_fold/blocks/block_compiler.py\", line 41, in __init__\n    super(_TaggedLoom, self).__init__(*args, **kwargs)\n  File \"/home/impadmin/anaconda2/envs/LSTM/lib/python3.6/site-packages/tensorflow_fold/loom/loom.py\", line 410, in __init__\n    self._setup_network()\n  File \"/home/impadmin/anaconda2/envs/LSTM/lib/python3.6/site-packages/tensorflow_fold/loom/loom.py\", line 621, in _setup_network\n    swap_memory=self._swap_memory)[1:]\n  File \"/home/impadmin/anaconda2/envs/LSTM/lib/python3.6/site-packages/tensorflow/python/ops/control_flow_ops.py\", line 2626, in while_loop\n    result = context.BuildLoop(cond, body, loop_vars, shape_invariants)\n  File \"/home/impadmin/anaconda2/envs/LSTM/lib/python3.6/site-packages/tensorflow/python/ops/control_flow_ops.py\", line 2459, in BuildLoop\n    pred, body, original_loop_vars, loop_vars, shape_invariants)\n  File \"/home/impadmin/anaconda2/envs/LSTM/lib/python3.6/site-packages/tensorflow/python/ops/control_flow_ops.py\", line 2409, in _BuildLoop\n    body_result = body(*packed_vars_for_body)\n  File \"/home/impadmin/anaconda2/envs/LSTM/lib/python3.6/site-packages/tensorflow_fold/loom/loom.py\", line 614, in loop_body\n    new_state = self._construct_loom_layer(depth, state)\n  File \"/home/impadmin/anaconda2/envs/LSTM/lib/python3.6/site-packages/tensorflow_fold/loom/loom.py\", line 711, in _construct_loom_layer\n    op_outputs = op.instantiate_batch(arg_inputs)\n  File \"/home/impadmin/anaconda2/envs/LSTM/lib/python3.6/site-packages/tensorflow_fold/blocks/loom_ops.py\", line 66, in instantiate_batch\n    outputs = self.tf_fn(*inputs)\n  File \"/home/impadmin/anaconda2/envs/LSTM/lib/python3.6/site-packages/tensorflow_fold/blocks/layers.py\", line 550, in __call__\n    result = self._layer_fn(*args, scope=self._vscope)\n  File \"/home/impadmin/anaconda2/envs/LSTM/lib/python3.6/site-packages/tensorflow/contrib/rnn/python/ops/core_rnn_cell_impl.py\", line 524, in __call__\n    output, new_state = self._cell(inputs, state, scope)\n  File \"<ipython-input-11-931ade2f97ba>\", line 27, in __call__\n    tf.concat([inputs, h0, h1], 1), 5 * self._num_units)\n  File \"/home/impadmin/anaconda2/envs/LSTM/lib/python3.6/site-packages/tensorflow/contrib/framework/python/ops/arg_scope.py\", line 177, in func_with_args\n    return func(*args, **current_args)\n  File \"/home/impadmin/anaconda2/envs/LSTM/lib/python3.6/site-packages/tensorflow/contrib/layers/python/layers/layers.py\", line 1409, in fully_connected\n    outputs = layer.apply(inputs)\n  File \"/home/impadmin/anaconda2/envs/LSTM/lib/python3.6/site-packages/tensorflow/python/layers/base.py\", line 303, in apply\n    return self.__call__(inputs, **kwargs)\n  File \"/home/impadmin/anaconda2/envs/LSTM/lib/python3.6/site-packages/tensorflow/python/layers/base.py\", line 273, in __call__\n    outputs = self.call(inputs, **kwargs)\n  File \"/home/impadmin/anaconda2/envs/LSTM/lib/python3.6/site-packages/tensorflow/python/layers/core.py\", line 145, in call\n    outputs = standard_ops.matmul(inputs, self.kernel)\n  File \"/home/impadmin/anaconda2/envs/LSTM/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py\", line 1855, in matmul\n    a, b, transpose_a=transpose_a, transpose_b=transpose_b, name=name)\n  File \"/home/impadmin/anaconda2/envs/LSTM/lib/python3.6/site-packages/tensorflow/python/ops/gen_math_ops.py\", line 1454, in _mat_mul\n    transpose_b=transpose_b, name=name)\n  File \"/home/impadmin/anaconda2/envs/LSTM/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 763, in apply_op\n    op_def=op_def)\n  File \"/home/impadmin/anaconda2/envs/LSTM/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 2395, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"/home/impadmin/anaconda2/envs/LSTM/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1264, in __init__\n    self._traceback = _extract_stack()\n\nInternalError (see above for traceback): Blas SGEMM launch failed : a.shape=(340, 900), b.shape=(900, 1500), m=340, n=1500, k=900\n\t [[Node: while/Function_35/tree_lstm/fully_connected/MatMul = MatMul[T=DT_FLOAT, transpose_a=false, transpose_b=false, _device=\"/job:localhost/replica:0/task:0/gpu:0\"](while/Function_35/tree_lstm/concat, while/Function_17/tree_lstm/fully_connected/MatMul/Enter)]]\n\t [[Node: while/Function_6/SparseSoftmaxCrossEntropyWithLogits/Shape_1/_109 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/gpu:0\", send_device_incarnation=1, tensor_name=\"edge_2569_while/Function_6/SparseSoftmaxCrossEntropyWithLogits/Shape_1\", tensor_type=DT_INT32, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](^_cloopwhile/Function_6/arg_1/Gather/_11)]]\n"
     ]
    }
   ],
   "source": [
    "best_accuracy = 0.0\n",
    "save_path = 'weights/sentiment_model'\n",
    "for epoch, shuffled in enumerate(td.epochs(train_set, EPOCHS), 1):\n",
    "  train_loss = train_epoch(shuffled)\n",
    "  f1_score = dev_eval(epoch, train_loss)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
